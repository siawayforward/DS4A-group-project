{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Air Quality Systems (AQS) Data\n",
    "## Part 1: Compiling Data using the AQS api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file aqs already exists.\n"
     ]
    }
   ],
   "source": [
    "# make a folder to save the data\n",
    "! mkdir aqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file(filename, df):\n",
    "    folder = 'aqs'\n",
    "    extension = 'csv'\n",
    "    path = '{}\\{}.{}'.format(folder, filename, extension)\n",
    "    df.to_csv(path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the AQS api: https://aqs.epa.gov/aqsweb/documents/data_api.html\n",
    "# the table explains the meaning of variables used: https://aqs.epa.gov/aqsweb/documents/data_api.html#variables\n",
    "# you have to sign up for the service - its super simple\n",
    "\n",
    "email = 'taylordisom@gmail.com'\n",
    "key = 'coppercrane22'\n",
    "creds = 'email={}&key={}'.format(email, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are daily records, so only one date is needed\n",
    "def get_aqs_byBox_url(date):\n",
    "    ''' from the CRITERIA param class:\n",
    "    42101 - Carbon monoxide\n",
    "    42401 - Sulfur dioxide\n",
    "    42602 - Nitrogen dioxide (NO2)\n",
    "    44201 - Ozone\n",
    "    81102 - PM10 Total 0-10um STP\n",
    "    88101 - PM2.5 - Local Conditions\n",
    "    ''' # api query limits: 5 params at a time\n",
    "    params = '44201,42401,42602,44201,88101'\n",
    "    parameters = 'param={}'.format(params)\n",
    "\n",
    "    # the start and end dates for the request in the format yyyymmdd\n",
    "    start_date = date\n",
    "    end_date = date\n",
    "    date_range = 'bdate={}&edate={}'.format(start_date, end_date)\n",
    "\n",
    "    # make a box (lat and long boundaries) to confine results,  (commented after 2 decimal places)\n",
    "    min_lat = 36.47 #4307 #the most south\n",
    "    max_lat = 38.52 #2384 # the most north\n",
    "    min_long = -123.41 #3342 # the most west / least east\n",
    "    max_long = -121.33 #1310 #the most east\n",
    "    box_bounds = 'minlat={}&maxlat={}&minlon={}&maxlon={}'.format(min_lat, max_lat, min_long, max_long)\n",
    "\n",
    "    byBox_query_base = 'https://aqs.epa.gov/data/api/dailyData/byBox'\n",
    "\n",
    "    # this is a sample query\n",
    "    # https://aqs.epa.gov/data/api/dailyData/byBox?email=test@aqs.api&key=test&param=44201&bdate=20150501&edate=20150502&minlat=33.3&maxlat=33.6&minlon=-87.0&maxlon=-86.7\n",
    "\n",
    "    # modularized the query\n",
    "    url = '{}?{}&{}&{}&{}'.format(byBox_query_base, creds, parameters, date_range, box_bounds)\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "def request_aqs_data(date):\n",
    "    url = get_aqs_byBox_url(date)\n",
    "    response = requests.get(url, stream=True)\n",
    "    if response.status_code == requests.codes.ok:\n",
    "        return response\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dates_for_range(start_date, end_date):\n",
    "    date_range = pd.date_range(start=start_date, end=end_date)\n",
    "    dates = [str(timestamp.date()).replace('-','') for timestamp in date_range]\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull the data from 1980 til now every 5 seconds (request usage limits)\n",
    "start_date = '19800101'\n",
    "# start_date = '20160505' # for testing\n",
    "end_date = '20201203'\n",
    "# end_date = '20160505' # for testing\n",
    "dates = get_dates_for_range(start_date, end_date)\n",
    "for date in dates:\n",
    "    response = request_aqs_data(date)\n",
    "    if response:\n",
    "        json_response = response.json()\n",
    "        if json_response['Data']:\n",
    "            data_dict = json_response['Data']\n",
    "            df = pd.DataFrame.from_dict(data = data_dict)\n",
    "            save_file(date, df)\n",
    "    time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the next step is to compile these daily files into a single file for each year\n",
    "# the same can be done for each decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are pregenereated data files: https://aqs.epa.gov/aqsweb/airdata/download_files.html\n",
    "# you can use the county code to filter the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Dataset Details\n",
    "https://aqs.epa.gov/aqsweb/airdata/FileFormats.html\n",
    "\n",
    "1. index: a unique identifier for the record / reading\n",
    "2. state_code: The FIPS code of the state in which the monitor resides. The numeric code for the state where the reading was observed (alphabetically, California is '06')\n",
    "3. county_code: The FIPS code of the county in which the monitor resides.The numeric code for the county where the reading was observed\n",
    "4. site_number: A unique number within the county identifying the site.\n",
    "5. parameter_code: The AQS code corresponding to the parameter measured by the monitor.\n",
    "6. poc: This is the “Parameter Occurrence Code” used to distinguish different instruments that measure the same parameter at the same site.\n",
    "7. latitude: The monitoring site’s angular distance north of the equator measured in decimal degrees.\n",
    "8. longitude: The monitoring site’s angular distance east of the prime meridian measured in decimal degrees.\n",
    "9. datum: The Datum associated with the Latitude and Longitude measures.\n",
    "10. parameter: The name or description assigned in AQS to the parameter measured by the monitor. Parameters may be pollutants or non-pollutants.\n",
    "11. sample_duration: The length of time that air passes through the monitoring device before it is analyzed (measured). So, it represents an averaging period in the atmosphere (for example, a 24-hour sample duration draws ambient air over a collection filter for 24 straight hours). For continuous monitors, it can represent an averaging time of many samples (for example, a 1-hour value may be the average of four one-minute samples collected during each quarter of the hour).\n",
    "12. pollutant_standard: A description of the ambient air quality standard rules used to aggregate statistics. (See description at beginning of document.)\n",
    "13. date_local: The calendar date for the summary. All daily summaries are for the local standard day (midnight to midnight) at the monitor.\n",
    "14. units_of_measure: The unit of measure for the parameter. QAD always returns data in the standard units for the parameter. Submitters are allowed to report data in any unit and EPA converts to a standard unit so that we may use the data in calculations.\n",
    "15. event_type: Indicates whether data measured during exceptional events are included in the summary. A wildfire is an example of an exceptional event; it is something that affects air quality, but the local agency has no control over. No Events means no events occurred. Events Included means events occurred and the data from them is included in the summary. Events Excluded means that events occurred but data form them is excluded from the summary. Concurred Events Excluded means that events occurred but only EPA concurred exclusions are removed from the summary. If an event occurred for the parameter in question, the data will have multiple records for each monitor.\n",
    "16. observation_count: The number of observations (samples) taken during the day.\n",
    "17. observation_percent: The percent representing the number of observations taken with respect to the number scheduled to be taken during the day. This is only calculated for monitors where measurements are required (e.g., only certain parameters).\n",
    "18. validity_indicator: An indication of whether the regulatory data completeness criteria for valid summary data have been met by the monitor for the year. Y means yes, N means no or that there are no regulatory completeness criteria for the parameter.\n",
    "19. arithmetic_mean: The average (arithmetic mean) value for the day.\n",
    "20. first_max_value: The highest value for the day.\n",
    "21. first_max_hour: The hour (on a 24-hour clock) when the highest value for the day (the previous field) was taken.\n",
    "22. aqi: The Air Quality Index for the day for the pollutant, if applicable.\n",
    "23. method_code: An internal system code indicating the method (processes, equipment, and protocols) used in gathering and measuring the sample. The method name is in the next column.\n",
    "24. method: A short description of the processes, equipment, and protocols used in gathering and measuring the sample.\n",
    "25. local_site_name: The name of the site (if any) given by the State, local, or tribal air pollution control agency that operates it.\n",
    "26. site_address: The approximate street address of the monitoring site.\n",
    "27. state: The name of the state where the monitoring site is located.\n",
    "28. county: The name of the county where the monitoring site is located.\n",
    "29. city: The name of the city where the monitoring site is located. This represents the legal incorporated boundaries of cities and not urban areas.\n",
    "30. cbsa_code: The code (ZIP Code) of the core bases statistical area (metropolitan area) where the monitoring site is located.\n",
    "31. cbsa: The name of the core bases statistical area (metropolitan area) where the monitoring site is located.\n",
    "32. date_of_last_change: The date the last time any numeric values in this record were updated in the AQS data system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "There is 40 years worth of data in the form of daily data that you can request from AQS. You can also find more granular data (hourly), but it seems like it would be overkill since our other data cannot also have such granularity. The daily data is about 70 KB per file/day. with 40 years of data, that's about 14,610 days and 1 GB of data (1 million KB). This is only pulling data within the set bounds of a defined lat/long box. we could also search by county, but I believe you cannot specify multiple counties in a single request. since there are usage limits for the size and frequency of requests, we decided to request data with the bounds of a box such that all of the counties we are interested in lie within the box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO add a small request to show what the data looks like\n",
    "\n",
    "# filename = 'aqs\\19821209.csv'\n",
    "# df = pd.read_csv(filename)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
